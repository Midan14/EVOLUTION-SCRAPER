# ğŸ° Evolution Gaming Baccarat Scraper

Scraper para extraer resultados en tiempo real de mesas de Baccarat de Evolution Gaming.

---

## ğŸš€ Â¿Primera vez? Lee la [GuÃ­a de Inicio RÃ¡pido](GUIA_INICIO_RAPIDO.md)

**Si eres nuevo** y quieres saber cÃ³mo descargar, instalar y ejecutar el proyecto paso a paso, **[haz clic aquÃ­ para ver la GuÃ­a de Inicio RÃ¡pido](GUIA_INICIO_RAPIDO.md)** ğŸ“–

---

## ğŸ¯ Objetivo

Extraer datos de la mesa **XXXtreme Lightning Baccarat** de Evolution Gaming desde:
- URL: `https://dragonslots-1.com/es/casino/game/evolution/xxxtremelightningbaccarat`

## ğŸ”§ MÃ©todo de ExtracciÃ³n

Este scraper utiliza **Playwright** (automatizaciÃ³n de navegador) para:

1. **Autenticarse** en el casino con credenciales de usuario
2. **Interceptar WebSocket/XHR** â€” Capturar mensajes del servidor de Evolution Gaming
3. **Extraer resultados** â€” Parsear los datos de cada ronda (Player/Banker/Tie, scores, etc.)
4. **Almacenar** â€” Guardar en base de datos SQLite y/o enviar a API externa
5. **Predecir** â€” Estrategias avanzadas de anÃ¡lisis (ML, gemelos, rachas, 4 roads)
6. **Notificar** â€” Enviar predicciones y resultados vÃ­a Telegram

## âš ï¸ Requisitos Previos

1. **Cuenta en DragonSlots** â€” Necesitas una cuenta activa
2. **Python 3.10+**
3. **Playwright** instalado con Chromium

## ğŸ“¦ InstalaciÃ³n

```bash
cd EVOLUTION-SCRAPER

# Crear entorno virtual
python3 -m venv venv
source venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt

# Instalar navegador Chromium para Playwright
playwright install chromium

# Configurar credenciales
cp .env.example .env
# Editar .env con tus credenciales
```

## ğŸ§ª Desarrollo

```bash
pip install -r requirements-dev.txt

# Lint
ruff check .

# Tests
pytest -q

# AuditorÃ­a de seguridad
pip-audit -r requirements.txt
```

Para dependencias reproducibles usa `requirements.lock` (generado con `pip-compile` desde `requirements.in`).

## ğŸš€ Uso

### Scraper + API Server (modo recomendado)

```bash
python run.py
```

Esto levanta el scraper de Playwright y un servidor API en `http://0.0.0.0:8899`.

### Solo scraper (sin API)

```bash
python run.py --scraper-only
```

### Solo API (servir datos existentes)

```bash
python run.py --api-only
```

### Modo headless (sin ventana de navegador)

```bash
python run.py --headless
```

### Bot avanzado con ML + Telegram

```bash
python dragon_bot_ml.py
```

### Docker

```bash
docker compose up -d
```

## ğŸ“¡ API Endpoints

Una vez levantado el servidor, la documentaciÃ³n interactiva estÃ¡ en `http://localhost:8899/docs`.

| Endpoint | DescripciÃ³n |
|---|---|
| `GET /` | InformaciÃ³n del servicio |
| `GET /health` | Estado de salud (DB, rounds capturados) |
| `GET /api/results` | Resultados recientes (parÃ¡metros: `limit`, `table_id`) |
| `GET /api/results/latest` | Ãšltimo resultado |
| `GET /api/results/history` | Historial (formato `full` o `simple`) |
| `GET /api/statistics` | EstadÃ­sticas por perÃ­odo (`hours`) |
| `GET /api/streak` | Racha actual (Player/Banker) |
| `GET /api/pattern` | PatrÃ³n reciente para Big Road |
| `GET /api/roads` | Big Road y roads derivados |

## ğŸ“Š Estructura de Datos ExtraÃ­dos

```json
{
    "round_id": "abc123",
    "timestamp": "2026-01-22T05:20:00Z",
    "result": "B",
    "player_score": 5,
    "banker_score": 7,
    "player_cards": ["â™ A", "â™¥4"],
    "banker_cards": ["â™¦K", "â™£7"],
    "lightning_cards": ["â™ 5", "â™¥8"],
    "multipliers": {"â™ 5": 2, "â™¥8": 5},
    "is_natural": false,
    "table_id": "xxxtremelightningbaccarat"
}
```

## ğŸ“ Estructura del Proyecto

```
EVOLUTION-SCRAPER/
â”œâ”€â”€ .env                          # Variables de entorno (NO subir a git)
â”œâ”€â”€ .env.example                  # Plantilla de variables de entorno
â”œâ”€â”€ .gitignore                    # Archivos excluidos de git
â”œâ”€â”€ README.md                     # Este archivo
â”œâ”€â”€ STRUCTURE.md                  # DocumentaciÃ³n detallada de estructura
â”œâ”€â”€ requirements.txt              # Dependencias Python
â”œâ”€â”€ requirements.in               # Input para pip-compile
â”œâ”€â”€ requirements.lock             # Dependencias pinned
â”œâ”€â”€ requirements-dev.txt          # Dependencias de desarrollo
â”œâ”€â”€ pyproject.toml                # ConfiguraciÃ³n de ruff y pytest
â”œâ”€â”€ Dockerfile                    # Imagen Docker
â”œâ”€â”€ docker-compose.yml            # OrquestaciÃ³n Docker
â”œâ”€â”€ run.py                        # Punto de entrada principal
â”‚
â”œâ”€â”€ src/                          # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                 # ConfiguraciÃ³n (env vars)
â”‚   â”œâ”€â”€ database.py               # Base de datos SQLite (async)
â”‚   â”œâ”€â”€ scraper.py                # Scraper Playwright + interceptores WS
â”‚   â”œâ”€â”€ api_server.py             # API REST (FastAPI)
â”‚   â””â”€â”€ api_scraper.py            # Scraper alternativo vÃ­a HTTP directo
â”‚
â”œâ”€â”€ tests/                        # Tests automatizados
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_scraper_extract.py   # Tests del scraper (extract, validate)
â”‚   â”œâ”€â”€ test_api_server.py        # Tests de la API REST
â”‚   â””â”€â”€ test_database.py          # Tests de la base de datos
â”‚
â”œâ”€â”€ baccarat_strategies.py        # Estrategias de predicciÃ³n (gemelos, rachas, etc.)
â”œâ”€â”€ road_analyzer.py              # AnÃ¡lisis Big Road y roads derivados
â”œâ”€â”€ advanced_agent.py             # Agente avanzado de anÃ¡lisis de mesa
â”œâ”€â”€ dragon_bot_ml.py              # Bot con ML + Telegram
â”œâ”€â”€ dragon_bot_advanced.py        # Bot avanzado (PostgreSQL)
â”œâ”€â”€ telegram_notifier.py          # Notificaciones Telegram
â”œâ”€â”€ backtest_offline.py           # Backtesting offline de estrategias
â”œâ”€â”€ generate_test_data.py         # Generador de datos de prueba
â”œâ”€â”€ test_ml_predictor.py          # Pruebas del predictor ML
â”‚
â”œâ”€â”€ deploy/                       # Scripts de despliegue en servidor
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ dragonbot.service         # Servicio systemd
â”‚   â”œâ”€â”€ deploy_from_mac.sh        # Deploy desde Mac via rsync
â”‚   â”œâ”€â”€ do_setup.sh               # Setup inicial del servidor
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ ws_samples/                   # Muestras de mensajes WebSocket
â”‚   â”œâ”€â”€ baccarat_newGame.json
â”‚   â”œâ”€â”€ baccarat_gameState.json
â”‚   â”œâ”€â”€ baccarat_resolved.json
â”‚   â”œâ”€â”€ baccarat_tableState.json
â”‚   â””â”€â”€ baccarat_encodedShoeState.json
â”‚
â”œâ”€â”€ data/                         # Base de datos SQLite (generado)
â”‚   â””â”€â”€ results.db
â”œâ”€â”€ logs/                         # Logs del scraper (generado)
â”‚   â””â”€â”€ scraper.log
â”œâ”€â”€ browser_data/                 # Datos de sesiÃ³n del navegador (generado)
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â””â”€â”€ ci.yml                # CI: lint + tests + audit
```

## ğŸ”’ Seguridad

- **NO** compartir credenciales â€” usa `.env` (incluido en `.gitignore`)
- Variables sensibles cargadas desde variables de entorno
- `storage_state.json` contiene cookies de sesiÃ³n â€” nunca subir a git
- CORS del API configurable vÃ­a `CORS_ORIGINS` en `.env`
- El scraper **NO** apuesta, solo observa

## ğŸ³ Docker

```bash
# Construir y ejecutar
docker compose up -d

# Ver logs
docker compose logs -f scraper

# Health check
curl http://localhost:8899/health
```

## ğŸš€ Deploy en Servidor (DigitalOcean)

Ver `deploy/README.md` para instrucciones detalladas de despliegue 24/7 con systemd.

```bash
# Desde tu Mac
bash deploy/deploy_from_mac.sh
```

## âš–ï¸ Disclaimer

Este proyecto es solo para fines educativos y de investigaciÃ³n.
El uso de scrapers puede violar los tÃ©rminos de servicio de los casinos.
Ãšsalo bajo tu propia responsabilidad.